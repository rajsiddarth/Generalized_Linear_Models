{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>NoOfChildren</th>\n",
       "      <th>MinAgeOfChild</th>\n",
       "      <th>MaxAgeOfChild</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>FrquncyOfPurchase</th>\n",
       "      <th>NoOfUnitsPurchased</th>\n",
       "      <th>FrequencyOFPlay</th>\n",
       "      <th>NoOfGamesPlayed</th>\n",
       "      <th>NoOfGamesBought</th>\n",
       "      <th>FavoriteChannelOfTransaction</th>\n",
       "      <th>FavoriteGame</th>\n",
       "      <th>TotalRevenueGenerated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>210</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2344</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>107.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>442</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>245</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>Favorite</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>382.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>424</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>1059</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>Favorite</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>135.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>261</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>365</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>Favorite</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>125.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>422</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>1066</td>\n",
       "      <td>102</td>\n",
       "      <td>44</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>335.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   City  NoOfChildren  MinAgeOfChild  MaxAgeOfChild  Tenure  \\\n",
       "0     1             2              3              8     210   \n",
       "1     1             2              3              6     442   \n",
       "2     1             4              3              5     424   \n",
       "3     1             1              6              6     261   \n",
       "4     1             3              6              9     422   \n",
       "\n",
       "   FrquncyOfPurchase  NoOfUnitsPurchased  FrequencyOFPlay  NoOfGamesPlayed  \\\n",
       "0                 11                  11             2344              108   \n",
       "1                 20                  20              245               22   \n",
       "2                 18                  18             1059              130   \n",
       "3                 11                   9              365               34   \n",
       "4                 44                  31             1066              102   \n",
       "\n",
       "   NoOfGamesBought FavoriteChannelOfTransaction FavoriteGame  \\\n",
       "0               10                      Uniform      Uniform   \n",
       "1                7                     Favorite      Uniform   \n",
       "2               18                     Favorite      Uniform   \n",
       "3               11                     Favorite      Uniform   \n",
       "4               44                      Uniform      Uniform   \n",
       "\n",
       "   TotalRevenueGenerated  \n",
       "0                 107.51  \n",
       "1                 382.40  \n",
       "2                 135.01  \n",
       "3                 125.00  \n",
       "4                 335.05  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading file\n",
    "url=\"https://raw.githubusercontent.com/rajsiddarth119/Generalized_Linear_Models/master/CustomerData.csv\"\n",
    "import pandas as pd\n",
    "data=pd.read_csv(url,header=0).dropna()\n",
    "#Dropping ID column\n",
    "data.drop(['CustomerID'],inplace=True,axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                              int64\n",
       "NoOfChildren                      int64\n",
       "MinAgeOfChild                     int64\n",
       "MaxAgeOfChild                     int64\n",
       "Tenure                            int64\n",
       "FrquncyOfPurchase                 int64\n",
       "NoOfUnitsPurchased                int64\n",
       "FrequencyOFPlay                   int64\n",
       "NoOfGamesPlayed                   int64\n",
       "NoOfGamesBought                   int64\n",
       "FavoriteChannelOfTransaction     object\n",
       "FavoriteGame                     object\n",
       "TotalRevenueGenerated           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City_1</th>\n",
       "      <th>City_2</th>\n",
       "      <th>FavoriteChannelOfTransaction_Favorite</th>\n",
       "      <th>FavoriteChannelOfTransaction_Uniform</th>\n",
       "      <th>FavoriteGame_Favorite</th>\n",
       "      <th>FavoriteGame_NONE</th>\n",
       "      <th>FavoriteGame_Uniform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   City_1  City_2  FavoriteChannelOfTransaction_Favorite  \\\n",
       "0     1.0     0.0                                    0.0   \n",
       "1     1.0     0.0                                    1.0   \n",
       "2     1.0     0.0                                    1.0   \n",
       "3     1.0     0.0                                    1.0   \n",
       "4     1.0     0.0                                    0.0   \n",
       "\n",
       "   FavoriteChannelOfTransaction_Uniform  FavoriteGame_Favorite  \\\n",
       "0                                   1.0                    0.0   \n",
       "1                                   0.0                    0.0   \n",
       "2                                   0.0                    0.0   \n",
       "3                                   0.0                    0.0   \n",
       "4                                   1.0                    0.0   \n",
       "\n",
       "   FavoriteGame_NONE  FavoriteGame_Uniform  \n",
       "0                0.0                   1.0  \n",
       "1                0.0                   1.0  \n",
       "2                0.0                   1.0  \n",
       "3                0.0                   1.0  \n",
       "4                0.0                   1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting city to factors\n",
    "data['City']=data['City'].astype('category')\n",
    "#Converting City,FavoriteChannelOfTransaction,FavoriteGame using dummies\n",
    "dummy_data=pd.get_dummies(data[['City','FavoriteChannelOfTransaction','FavoriteGame']])\n",
    "dummy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoOfChildren                               int64\n",
       "MinAgeOfChild                              int64\n",
       "MaxAgeOfChild                              int64\n",
       "Tenure                                     int64\n",
       "FrquncyOfPurchase                          int64\n",
       "NoOfUnitsPurchased                         int64\n",
       "FrequencyOFPlay                            int64\n",
       "NoOfGamesPlayed                            int64\n",
       "NoOfGamesBought                            int64\n",
       "TotalRevenueGenerated                    float64\n",
       "City_1                                   float64\n",
       "City_2                                   float64\n",
       "FavoriteChannelOfTransaction_Favorite    float64\n",
       "FavoriteChannelOfTransaction_Uniform     float64\n",
       "FavoriteGame_Favorite                    float64\n",
       "FavoriteGame_NONE                        float64\n",
       "FavoriteGame_Uniform                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final data frame\n",
    "data.drop(['City','FavoriteChannelOfTransaction','FavoriteGame'],inplace=True,axis=1)\n",
    "final_data=pd.concat([data,dummy_data],axis=1)\n",
    "final_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y=final_data.loc[:,['TotalRevenueGenerated']]\n",
    "X=final_data.loc[:,final_data.columns.difference(Y.columns)]\n",
    "\n",
    "#Splitting into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ridge regression with initial alpha =1\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "ridge_model=Ridge(normalize=True,random_state=10,alpha=1,fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE on training data is : 18.830000\n",
      "MAPE on test data is : 18.680000\n"
     ]
    }
   ],
   "source": [
    "#Fitting Ridge model\n",
    "model=ridge_model.fit(X=X_train,y=y_train)\n",
    "\n",
    "#Predicting on train data\n",
    "pred=model.predict(X_train)\n",
    "pred_test=model.predict(X_test)\n",
    "\n",
    "#Error metrics on train data\n",
    "#Writing function for calculating MAPE\n",
    "from sklearn.utils import check_array\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true,y_pred=check_array(y_true),check_array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "print (\"MAPE on training data is : %f\" %(round(mean_absolute_percentage_error(y_train,pred),2)))\n",
    "\n",
    "#Predicting on test data\n",
    "pred_test=model.predict(X_test)\n",
    "print (\"MAPE on test data is : %f\" %(round(mean_absolute_percentage_error(y_test,pred_test),2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.34606988e+00   4.34606988e+00   7.43609049e+00  -7.43609049e+00\n",
      "    3.89775990e+00   1.73916110e+01  -6.65328460e+00   2.75234709e-03\n",
      "    9.39636721e+00  -2.32417300e-01   1.00458613e+00   2.82972964e+00\n",
      "   -1.05233634e+01  -2.89703697e-02   9.31769779e+00  -1.49253342e-02]]\n",
      "alpha value is 0.005000\n"
     ]
    }
   ],
   "source": [
    "#For different values of alpha : grid search\n",
    "alp=10**np.linspace(10,-2,100)*0.5\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "modelCV=RidgeCV(alphas=alp,normalize=True)\n",
    "modelCV.fit(X_train,y_train)\n",
    "print (modelCV.coef_)\n",
    "print (\"alpha value is %f\"%(modelCV.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Ridge(alpha=0.0050000000000000001, copy_X=True, fit_intercept=True,\n",
      "   max_iter=None, normalize=True, random_state=10, solver='auto',\n",
      "   tol=0.001),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': array([  5.00000e+09,   3.78232e+09, ...,   6.60971e-03,   5.00000e-03])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "0.693745113698\n",
      "0.005\n"
     ]
    }
   ],
   "source": [
    "#Grid Search Method 2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alp))\n",
    "grid.fit(X_train,y_train)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE on training data is : 18.830000\n",
      "MAPE on test data is : 18.680000\n"
     ]
    }
   ],
   "source": [
    "#Training Model with best alpha value\n",
    "ridge_model=Ridge(normalize=True,random_state=10,alpha=modelCV.alpha_,fit_intercept=True)\n",
    "\n",
    "#Fitting Ridge model\n",
    "model2=ridge_model.fit(X=X_train,y=y_train)\n",
    "\n",
    "#Predicting on train data\n",
    "pred2=model2.predict(X_train)\n",
    "pred_test2=model2.predict(X_test)\n",
    "\n",
    "#Error metrics on train data\n",
    "\n",
    "print (\"MAPE on training data is : %f\" %(round(mean_absolute_percentage_error(y_train,pred2),2)))\n",
    "\n",
    "#Predicting on test data\n",
    "pred_test2=model2.predict(X_test)\n",
    "print (\"MAPE on test data is : %f\" %(round(mean_absolute_percentage_error(y_test,pred_test2),2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of lasso is similar to Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Lasso in module sklearn.linear_model.coordinate_descent:\n",
      "\n",
      "class Lasso(ElasticNet)\n",
      " |  Linear Model trained with L1 prior as regularizer (aka the Lasso)\n",
      " |  \n",
      " |  The optimization objective for Lasso is::\n",
      " |  \n",
      " |      (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
      " |  \n",
      " |  Technically the Lasso model is optimizing the same objective function as\n",
      " |  the Elastic Net with ``l1_ratio=1.0`` (no L2 penalty).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <lasso>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  alpha : float, optional\n",
      " |      Constant that multiplies the L1 term. Defaults to 1.0.\n",
      " |      ``alpha = 0`` is equivalent to an ordinary least square, solved\n",
      " |      by the :class:`LinearRegression` object. For numerical\n",
      " |      reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
      " |      Given this, you should use the :class:`LinearRegression` object.\n",
      " |  \n",
      " |  fit_intercept : boolean\n",
      " |      whether to calculate the intercept for this model. If set\n",
      " |      to false, no intercept will be used in calculations\n",
      " |      (e.g. data is expected to be already centered).\n",
      " |  \n",
      " |  normalize : boolean, optional, default False\n",
      " |      If ``True``, the regressors X will be normalized before regression.\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to ``False``.\n",
      " |      When the regressors are normalized, note that this makes the\n",
      " |      hyperparameters learnt more robust and almost independent of the number\n",
      " |      of samples. The same property is not valid for standardized data.\n",
      " |      However, if you wish to standardize, please use\n",
      " |      :class:`preprocessing.StandardScaler` before calling ``fit`` on an estimator\n",
      " |      with ``normalize=False``.\n",
      " |  \n",
      " |  copy_X : boolean, optional, default True\n",
      " |      If ``True``, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  precompute : True | False | array-like, default=False\n",
      " |      Whether to use a precomputed Gram matrix to speed up\n",
      " |      calculations. If set to ``'auto'`` let us decide. The Gram\n",
      " |      matrix can also be passed as argument. For sparse input\n",
      " |      this option is always ``True`` to preserve sparsity.\n",
      " |  \n",
      " |  max_iter : int, optional\n",
      " |      The maximum number of iterations\n",
      " |  \n",
      " |  tol : float, optional\n",
      " |      The tolerance for the optimization: if the updates are\n",
      " |      smaller than ``tol``, the optimization code checks the\n",
      " |      dual gap for optimality and continues until it is smaller\n",
      " |      than ``tol``.\n",
      " |  \n",
      " |  warm_start : bool, optional\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |  \n",
      " |  positive : bool, optional\n",
      " |      When set to ``True``, forces the coefficients to be positive.\n",
      " |  \n",
      " |  selection : str, default 'cyclic'\n",
      " |      If set to 'random', a random coefficient is updated every iteration\n",
      " |      rather than looping over features sequentially by default. This\n",
      " |      (setting to 'random') often leads to significantly faster convergence\n",
      " |      especially when tol is higher than 1e-4.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, or None (default)\n",
      " |      The seed of the pseudo random number generator that selects\n",
      " |      a random feature to update. Useful only when selection is set to\n",
      " |      'random'.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array, shape (n_features,) | (n_targets, n_features)\n",
      " |      parameter vector (w in the cost function formula)\n",
      " |  \n",
      " |  sparse_coef_ : scipy.sparse matrix, shape (n_features, 1) |             (n_targets, n_features)\n",
      " |      ``sparse_coef_`` is a readonly property derived from ``coef_``\n",
      " |  \n",
      " |  intercept_ : float | array, shape (n_targets,)\n",
      " |      independent term in decision function.\n",
      " |  \n",
      " |  n_iter_ : int | array-like, shape (n_targets,)\n",
      " |      number of iterations run by the coordinate descent solver to reach\n",
      " |      the specified tolerance.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import linear_model\n",
      " |  >>> clf = linear_model.Lasso(alpha=0.1)\n",
      " |  >>> clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n",
      " |  Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      " |     normalize=False, positive=False, precompute=False, random_state=None,\n",
      " |     selection='cyclic', tol=0.0001, warm_start=False)\n",
      " |  >>> print(clf.coef_)\n",
      " |  [ 0.85  0.  ]\n",
      " |  >>> print(clf.intercept_)\n",
      " |  0.15\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  lars_path\n",
      " |  lasso_path\n",
      " |  LassoLars\n",
      " |  LassoCV\n",
      " |  LassoLarsCV\n",
      " |  sklearn.decomposition.sparse_encode\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The algorithm used to fit the model is coordinate descent.\n",
      " |  \n",
      " |  To avoid unnecessary memory duplication the X argument of the fit method\n",
      " |  should be directly passed as a Fortran-contiguous numpy array.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Lasso\n",
      " |      ElasticNet\n",
      " |      sklearn.linear_model.base.LinearModel\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  path = enet_path(X, y, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      " |      Compute elastic net path with coordinate descent\n",
      " |      \n",
      " |      The elastic net optimization function varies for mono and multi-outputs.\n",
      " |      \n",
      " |      For mono-output tasks it is::\n",
      " |      \n",
      " |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      " |          + alpha * l1_ratio * ||w||_1\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      " |      \n",
      " |      For multi-output tasks it is::\n",
      " |      \n",
      " |          (1 / (2 * n_samples)) * ||Y - XW||^Fro_2\n",
      " |          + alpha * l1_ratio * ||W||_21\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      " |      \n",
      " |      Where::\n",
      " |      \n",
      " |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      " |      \n",
      " |      i.e. the sum of norm of each row.\n",
      " |      \n",
      " |      Read more in the :ref:`User Guide <elastic_net>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like}, shape (n_samples, n_features)\n",
      " |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      " |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      " |          can be sparse.\n",
      " |      \n",
      " |      y : ndarray, shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          Target values\n",
      " |      \n",
      " |      l1_ratio : float, optional\n",
      " |          float between 0 and 1 passed to elastic net (scaling between\n",
      " |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso\n",
      " |      \n",
      " |      eps : float\n",
      " |          Length of the path. ``eps=1e-3`` means that\n",
      " |          ``alpha_min / alpha_max = 1e-3``\n",
      " |      \n",
      " |      n_alphas : int, optional\n",
      " |          Number of alphas along the regularization path\n",
      " |      \n",
      " |      alphas : ndarray, optional\n",
      " |          List of alphas where to compute the models.\n",
      " |          If None alphas are set automatically\n",
      " |      \n",
      " |      precompute : True | False | 'auto' | array-like\n",
      " |          Whether to use a precomputed Gram matrix to speed up\n",
      " |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      " |          matrix can also be passed as argument.\n",
      " |      \n",
      " |      Xy : array-like, optional\n",
      " |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      " |          only when the Gram matrix is precomputed.\n",
      " |      \n",
      " |      copy_X : boolean, optional, default True\n",
      " |          If ``True``, X will be copied; else, it may be overwritten.\n",
      " |      \n",
      " |      coef_init : array, shape (n_features, ) | None\n",
      " |          The initial values of the coefficients.\n",
      " |      \n",
      " |      verbose : bool or integer\n",
      " |          Amount of verbosity.\n",
      " |      \n",
      " |      params : kwargs\n",
      " |          keyword arguments passed to the coordinate descent solver.\n",
      " |      \n",
      " |      return_n_iter : bool\n",
      " |          whether to return the number of iterations or not.\n",
      " |      \n",
      " |      positive : bool, default False\n",
      " |          If set to True, forces coefficients to be positive.\n",
      " |      \n",
      " |      check_input : bool, default True\n",
      " |          Skip input validation checks, including the Gram matrix when provided\n",
      " |          assuming there are handled by the caller when check_input=False.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      alphas : array, shape (n_alphas,)\n",
      " |          The alphas along the path where models are computed.\n",
      " |      \n",
      " |      coefs : array, shape (n_features, n_alphas) or             (n_outputs, n_features, n_alphas)\n",
      " |          Coefficients along the path.\n",
      " |      \n",
      " |      dual_gaps : array, shape (n_alphas,)\n",
      " |          The dual gaps at the end of the optimization for each alpha.\n",
      " |      \n",
      " |      n_iters : array-like, shape (n_alphas,)\n",
      " |          The number of iterations taken by the coordinate descent optimizer to\n",
      " |          reach the specified tolerance for each alpha.\n",
      " |          (Is returned when ``return_n_iter`` is set to True).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See examples/linear_model/plot_lasso_coordinate_descent_path.py for an example.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      MultiTaskElasticNet\n",
      " |      MultiTaskElasticNetCV\n",
      " |      ElasticNet\n",
      " |      ElasticNetCV\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset([])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ElasticNet:\n",
      " |  \n",
      " |  decision_function(*args, **kwargs)\n",
      " |      DEPRECATED:  and will be removed in 0.19\n",
      " |      \n",
      " |      Decision function of the linear model\n",
      " |      \n",
      " |              Parameters\n",
      " |              ----------\n",
      " |              X : numpy array or scipy.sparse matrix of shape (n_samples, n_features)\n",
      " |      \n",
      " |              Returns\n",
      " |              -------\n",
      " |              T : array, shape (n_samples,)\n",
      " |                  The predicted decision function\n",
      " |  \n",
      " |  fit(self, X, y, check_input=True)\n",
      " |      Fit model with coordinate descent.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : ndarray or scipy.sparse matrix, (n_samples, n_features)\n",
      " |          Data\n",
      " |      \n",
      " |      y : ndarray, shape (n_samples,) or (n_samples, n_targets)\n",
      " |          Target\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Coordinate descent is an algorithm that considers each column of\n",
      " |      data at a time hence it will automatically convert the X input\n",
      " |      as a Fortran-contiguous numpy array if necessary.\n",
      " |      \n",
      " |      To avoid memory re-allocation it is advised to allocate the\n",
      " |      initial data in memory directly using that format.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from ElasticNet:\n",
      " |  \n",
      " |  sparse_coef_\n",
      " |      sparse representation of the fitted ``coef_``\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the regression\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      Best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -8.69903784e+00   1.20886707e-16   1.46903308e+01  -0.00000000e+00\n",
      "   0.00000000e+00   1.10986580e+01  -9.38753674e+00   2.29464522e-03\n",
      "   9.90793257e+00  -1.80225839e-01   8.97800204e-01   2.34466378e+00\n",
      "  -1.09232707e+01  -1.79010018e-02   9.15679817e+00  -1.23723497e-02]\n",
      "alpha value is 0.005000\n",
      "MAPE on training data is : 42.430000\n",
      "MAPE on test data is : 42.310000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sid\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\sid\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Lasso Regression\n",
    "from sklearn.linear_model import Lasso,LassoCV\n",
    "import numpy as np\n",
    "LassoCV_model=LassoCV(alphas=alp,normalize=True)\n",
    "LassoCV_model.fit(X_train,y_train)\n",
    "print (LassoCV_model.coef_)\n",
    "print (\"alpha value is %f\"%(LassoCV_model.alpha_))\n",
    "\n",
    "#Training Lasso Model with best alpha value\n",
    "Lasso_model=Lasso(normalize=True,random_state=10,alpha=LassoCV_model.alpha_,fit_intercept=True)\n",
    "\n",
    "#Fitting Ridge model\n",
    "model5=Lasso_model.fit(X=X_train,y=y_train)\n",
    "\n",
    "#Predicting on train data\n",
    "pred5=model5.predict(X_train)\n",
    "pred_test5=model5.predict(X_test)\n",
    "\n",
    "#Error metrics on train data\n",
    "\n",
    "print (\"MAPE on training data is : %f\" %(round(mean_absolute_percentage_error(y_train,pred5),2)))\n",
    "\n",
    "#Predicting on test data\n",
    "\n",
    "print (\"MAPE on test data is : %f\" %(round(mean_absolute_percentage_error(y_test,pred_test5),2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE on training data is : 33.650000\n",
      "MAPE on test data is : 33.400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sid\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\sid\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1.92283091e+00,  -1.92287387e+00,   2.14866310e+00,\n",
       "        -2.14856498e+00,   4.70623207e-01,   4.85648657e+00,\n",
       "        -1.38906810e+00,   9.59626547e-04,   7.59669729e-01,\n",
       "        -1.22952181e-02,   7.28685016e-02,   8.44611114e-01,\n",
       "         4.31546023e-01,   2.62416402e-02,   1.06482384e+00,\n",
       "         9.23284182e-03])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model with Elastic net Regularization\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "\n",
    "#Training Model with best alpha value\n",
    "elastic_model=ElasticNetCV(alphas=alp,random_state=12,normalize=True)\n",
    "\n",
    "#Fitting Ridge model\n",
    "model3=elastic_model.fit(X=X_train,y=y_train)\n",
    "\n",
    "#Predicting on train data\n",
    "pred3,pred_test3=model3.predict(X_train),model3.predict(X_test)\n",
    "\n",
    "#Error metrics on train data\n",
    "\n",
    "print (\"MAPE on training data is : %f\" %(round(mean_absolute_percentage_error(y_train,pred3),2)))\n",
    "\n",
    "#Predicting on test data\n",
    "pred_test2=model2.predict(X_test)\n",
    "print (\"MAPE on test data is : %f\" %(round(mean_absolute_percentage_error(y_test,pred_test3),2)))\n",
    "model3.alpha_\n",
    "model3.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
